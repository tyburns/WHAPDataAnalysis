---
title: "Equations to calculate mass from seedhead dimensions"
author: "Emilio A. Laca"
date: "10/27/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(car)
library(magrittr)
library(readxl)
library(caret)

```

## Data from summer 2021

```{r readData}

sh_dim <- read_excel("SeedDimensionsMDC2021.xlsx", sheet = "dimensions")

table(sh_dim$spp, sh_dim$taxonID) # One error in Swamp timothy to correct in Excel
# I already corrected the version in GitHub, but not the file in FWS server.

sh_mass <- read_excel("SeedDimensionsMDC2021.xlsx", sheet = "weights")

```

For some species we grouped several similar seedheads in a bag. Average dimensions have to be calculated for those and then dimensions and mass have to be merged.

Mass was measured per bag, so the mass of each bag has to be divided by the number of seed heads in the bag. The number of seed heads per bag is obtaining by counting how many rows there are for each bag id in the dimensions data.

```{r mergeDimesionsMass, warning=FALSE}

avg_sh_dim <- sh_dim %>%
  group_by(LIT, spp, taxonID, bag_id) %>%
  summarise(f2t_length_mm = mean(f2t_length_mm),
            length_mm = mean(length_mm),
            width_mm =  mean(width_mm),
            n_sh = n(),
            .groups = "drop")

sh_dim_mass <- full_join(avg_sh_dim, sh_mass) %>%
  mutate(mass_mg = mass_mg/n_sh)

# Save file
saveRDS(sh_dim_mass, "sh_dim_MDC2021.rds")

```

## Smartweed

### Graphical exploration of data

Some models use an a priori combination of dimensions to calculate volume and then regress mass on volume.

```{r sw_exploreData}

sw_dim <- sh_dim_mass %>%
  dplyr::filter(spp == "Smartweed") %>%
  mutate(vol_mm3 = pi * (width_mm/2)^2 * length_mm)

sw_dim %>% dplyr::select(mass_mg, length_mm, width_mm, vol_mm3) %>% pairs()

scatterplot(mass_mg ~ vol_mm3, sw_dim, log = "xy") # Log transf. is promising

sw_dim[which.max(sw_dim$vol_mm3), ] # extreme volume

sw_dim %>% dplyr::select(length_mm, width_mm) %>% plot()
abline(0, 1) # One seed head has width 8 larger than width; nonsense. remove

which(sw_dim$length_mm < 4 & sw_dim$width_mm == 8)

sw_dim %<>% dplyr::filter(
  not(vol_mm3 == max(vol_mm3) | (sw_dim$length_mm < 4 & sw_dim$width_mm == 8))
) # to exclude oddballs

```

An outlier with unusual width was removed.

A quick read of several papers reporting equations to assess seed mass based on plant dimensions revealed that none of their equations included transformations. I find it hard to believe that their variances about predicted values were the same, regardless of the size of seed heads and plants. It is almost a physical necessity that larger plants exhibit more variance (in absolute terms) than smaller plants. Because of the restriction to be positive, it is almost impossible for small plants or seedheads to have the same variance as larger ones. Strictly speaking, mass cannot have a normal distribution, and it is very likely to deviate more from normality as the mean becomes small (thus, the lognormal distribution, or the log transformation of mass).


## Modeling

### Smartweed (sw)
#### Volume as single predictor
First we try a simple linear model with volume.

```{r sw_linearVolume, warning=FALSE}

sw_m1 <- lm(mass_mg ~ vol_mm3, data = sw_dim)

summary(sw_m1)

opar <- par(mfrow = c(2,2)); plot(sw_m1); par(opar)

```

Variance increases with fitted value and there is indication of slight non-linearity. Try a Box-Cox transformation. This transformation is

$$ Y' = \frac{Y^\lambda - 1}{\lambda} \qquad \quad \text{for lambda not 0, and} \\
\quad\\
Y' = log(Y) \qquad \quad \text{for lambda = 0}$$

Predictions resulting from the model have to be backtransformed into mg by the inverse transformation (only the case for lambda not 0 shown):


$$ Y = (\lambda \enspace Y' + 1)^ {\enspace (1/\lambda)}$$

which in R code is `(Y = lambda * Y_prime + 1) ^ (1/lambda)`.

```{r sw_transformedVolume, warning=FALSE}

# Get optimal lambda
sw_lamb1 <- powerTransform(lm(mass_mg ~ vol_mm3,
                              data = sw_dim)) %>%
  coef(round = TRUE) %>%
  unname()

# Fit model with transformed Y
sw_m2 <- lm(bcPower(mass_mg, lambda = sw_lamb1) ~ vol_mm3,
               data = sw_dim)

opar <- par(mfrow = c(2,2)); plot(sw_m2); par(opar)

# Some nonlinearity remains, which increases the variance at the right side
# Try an additional transformation in volume

sw_m3 <- lm(bcPower(mass_mg, lambda = sw_lamb1) ~ log(vol_mm3),
               data = sw_dim)

opar <- par(mfrow = c(2,2)); plot(sw_m3); par(opar)

summary(sw_m3)

```


#### Length as a single predictor

Width was not measured in any refuge other than MDC in 2021. In order to calculate mass of smartweed for the other refuges we need to make a model with lenght as a single predictor. Keep in mind that the only training data available for d2m is from MDC.

```{r sw_transformedLength, warning=FALSE}

# Get optimal lambda
sw_lamb2 <- powerTransform(lm(mass_mg ~ log(length_mm),
                              data = sw_dim)) %>%
  coef(round = TRUE) %>%
  unname()

# Fit model with transformed Y
sw_m4 <- lm(bcPower(mass_mg, lambda = sw_lamb2) ~ length_mm,
               data = sw_dim)

opar <- par(mfrow = c(2,2)); plot(sw_m4); par(opar)

# Some nonlinearity remains, which increases the variance at the right side
# Try an additional transformation in volume

sw_m5 <- lm(bcPower(mass_mg, lambda = sw_lamb2) ~ log(length_mm),
               data = sw_dim)

opar <- par(mfrow = c(2,2)); plot(sw_m5); par(opar) # outlier 380

summary(sw_m5)

```


#### Multiple predictors

```{r sw_multiplePreds}

sw_lamb3 <- powerTransform(lm(mass_mg ~ log(vol_mm3) + width_mm + length_mm,
                              data = sw_dim)) %>%
  coef(round = TRUE) %>%
  unname()

sw_m6 <- lm(bcPower(mass_mg, lambda = sw_lamb3) ~ log(vol_mm3) +
              width_mm + length_mm,
            data = sw_dim)

opar <- par(mfrow = c(2,2)); plot(sw_m6); par(opar)

summary(sw_m6)


sw_m7 <- lm(bcPower(mass_mg, lambda = sw_lamb3) ~ log(vol_mm3) + length_mm,
            data = sw_dim)

opar <- par(mfrow = c(2,2)); plot(sw_m7); par(opar)

summary(sw_m7)

```


#### Compare models with multiple predictors

Models sw_m4 and sw_m5 are both good. It is necessary to determine which one is better. sw_m4 appears to be slightly better in terms of residual variance, but it may not be as good in prediction errors. This is assessed with cross validation.

```{r sw_cv}

# Add transformed response to data
sw_dim %<>% mutate(bc_mass_gm = bcPower(mass_mg, lambda = sw_lamb3))

# Training control
train_control <- trainControl(method = "repeatedcv",
                              number = 10,
                              repeats = 3)

sw_m6_cv <- train(bc_mass_gm ~
                    log(vol_mm3) +
                    width_mm +
                    length_mm,
                  data = sw_dim,
                  method = "lm",
                  trControl = train_control)


sw_m7_cv <- train(bc_mass_gm ~
                    log(vol_mm3) +
                    length_mm,
                  data = sw_dim,
                  method = "lm",
                  trControl = train_control)

# Collect results for comparison
results <- resamples(list(sw_m6_cv = sw_m6_cv,
                          sw_m7_cv = sw_m7_cv))

# Summarize and plot the distributions
summary(results)
bwplot(results)

```

Model sw_m6 performs slightly better.

```{r sw_saveData}

saveRDS(sw_dim, "swdat.rds")

```

